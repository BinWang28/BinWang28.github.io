<!DOCTYPE HTML>
<html lang="en">
  
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Bin Wang (王斌)</title>
  
  <meta name="author" content="Bin Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-144973743-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-144973743-1');
  </script>


</head>



<body>
  
  <div class="sidenav">
    <a href="#top">Home</a>
    <a href="#news">News</a>
    <a href="#research">Research</a>
    <a href="#service">Services</a>
    <a href="#fun_facts">Fun Facts</a>
  </div>

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#283747"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle;color:#f7f7f7">
              <p style="text-align:left; color:#f7f7f7">
                <name>Bin Wang (王斌)</name>
              </p>
              <p>
                Bin Wang receives his Ph.D. degree from University of Southern California (USC) under the supervision of Prof. C.-C. Jay Kuo in 2021 and his B.Eng degree from University of Electronic Science and Technology of China (UESTC) in 2017. He is currently a research fellow at National University of Singapore.
                His research interests focus on natural language processing, especially representation learning.

                I obtained my PhD degree in Electrical Engineering from <a href="http://mcl.usc.edu/" style="color: rgb(0, 166, 255)">University of Southern California (USC)</a> in May 2021, where I mainly working on Language Processing and Multimedia problems, advised by <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh" style="color:rgb(0, 166, 255)"> Prof. C.-C. Jay Kuo </a>.
                Before that, I got my bachelor's degree from <a href="https://en.uestc.edu.cn/" style="color: rgb(0, 166, 255)"=>University of Electronic Science and Technology of China (UESTC)</a> in 2017.
              </p>
              <p style="text-align:center">
                <a href="mailto:bwang28c@gmail.com" style="color:rgb(0, 166, 255)">Email</a> &nbsp/&nbsp
                <a href="data/Bin-CV.pdf" style="color:rgb(0, 166, 255)">CV</a> &nbsp/&nbsp
                <a href="data/Bin-bio.txt" style="color:rgb(0, 166, 255)">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=jUrRMv4AAAAJ&hl=en" style="color:rgb(0, 166, 255)">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/BinWang28" style="color:rgb(0, 166, 255)">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:25%;max-width:25%">
              <a><img style="width:100%;max-width:100%" alt="profile photo" src="images/bin-circle-cropped.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading id="news">News</heading>
            <br>
            <br>
            <ol style="list-style-position:outside; list-style-type: inherit;padding-left: 3em; columns: 1;">
            <li> <b>[05/08/2021]</b>&nbsp;&nbsp; One paper on Anomaly Image Localization is now on <a href="https://arxiv.org/abs/2105.03797">Arxiv</a>. </li>
            <li> <b>[04/14/2021]</b>&nbsp;&nbsp; One paper on Dynamic Texture Synthesis is now on <a href="https://arxiv.org/abs/2104.05940">Arxiv</a>. </li>
            <li> <b>[04/10/2021]</b>&nbsp;&nbsp; One paper on Commensense Knolwegde Graph accepted to <a href="https://www.ijcnn.org/">IJCNN 2021</a>. </li>
            <li> <b>[03/15/2021]</b>&nbsp;&nbsp; I passed my Ph.D. defense. Officially MCL alumni: <a href="http://mcl.usc.edu/people/alumni-phds-and-postdocs/">page</a>. </li>
            <li> <b>[Old Ones]: </b> <a href="old_news.html">Here!</a> </li>
            </ol>
          </td>
        </tr>
      </tbody></table>


      <table id='research' style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              My research interests span the areas of natural language processing, multimedia processing and machine learning. 
              I have specific interest in representation learning and self-supervised learning.
              Representative papers are <span class="highlight">highlighted</span>.
            </p>
          </td>
        </tr>
      </tbody></table>

      <!-- Paper 13 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/anomalyhop.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2105.03797">
          <papertitle>AnomalyHop: An SSL-based Image Anomaly Localization Method</papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=yCX2_n4AAAAJ&hl=en"> Kaitai Zhang*</a>,
          <strong> Bin Wang*</strong>,
          <a href="https://www.linkedin.com/in/weiwang16/"> Wei Wang</a>,
          <a href="https://scholar.google.com/citations?user=YxnQx40AAAAJ&hl=en"> Fahad Sohrab</a>,
          <a href="https://scholar.google.com/citations?user=cHukfSUAAAAJ&hl=en"> Moncef Gabbouj</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>IEEE Signal Processing Letters (Under Review)</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2105.03797">arxiv</a>
          /
          <a href="https://github.com/BinWang28/AnomalyHop">code</a>
          <p></p>
          <p>Comparing with state-of-the-art image anomaly localization methods based on deep neural networks (DNNs), AnomalyHop is mathematically transparent, easy to train, and fast in its inference speed.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 12 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/dt.gif' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2104.05940">
          <papertitle>Dynamic Texture Synthesis by Incorporating Long-range Spatial and Temporal Correlations</papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=yCX2_n4AAAAJ&hl=en"> Kaitai Zhang</a>,
          <strong> Bin Wang</strong>,
          <a href="https://scholar.google.com/citations?user=uWIBdm8AAAAJ&hl=en"> Hong-Shuo Chen</a>,
          <a href="https://scholar.google.com/citations?user=9el0ufkAAAAJ&hl=en"> Ye Wang</a>,
          <a href="https://www.linkedin.com/in/shiyu-mou-110623ba/"> Shiyu Mou</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>Conference (Under Review)</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2104.05940">arxiv</a>
          /
          <p></p>
          <p>Maintain spatial and temporal consistency in synthesized dynamic textures. We incorporate a new loss term, called the Shifted Gram loss, to capture the structural and long-range correlation of the reference texture video.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 11 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/graphhop.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2101.02326">
          <papertitle>GraphHop: An Enhanced Label Propagation Method for Node Classification</papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=wKjXhH8AAAAJ&hl=en&oi=sra"> Tian Xie</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS) (Under Review)</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2101.02326">arxiv</a>
          /
          <a href="https://github.com/TianXieUSC/GraphHop">code</a>
          <p></p>
          <p>With proper initial label vector embeddings, each iteration of GraphHop contains two steps: 1) label aggregation and 2) label update. The iterative procedure exploits the neighborhood information and enables GraphHop to perform well in an extremely small label rate setting and scale well for very large graphs.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 10 -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="inductive_stop()" onmouseover="inductive_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inductive_image'><video  width=100% height=100% muted autoplay loop>
                  <img src='images/inductive-memo.jpg' width="160"></div>
                  <img src='images/inductive-memo.jpg' width="160">
                </div>
              <script type="text/javascript">
                function inductive_start() {
                  document.getElementById('inductive_image').style.opacity = "1";
                }

                function inductive_stop() {
                  document.getElementById('inductive_image').style.opacity = "0";
                }
                inductive_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2009.09263">
              <papertitle>Inductive Learning on Commonsense Knowledge Graph Completion</papertitle>
              </a>
              <br>
              <strong>Bin Wang</strong>,
              <a href="https://scholar.google.com/citations?user=ga5aRGkAAAAJ&hl=en"> Guangtao Wang</a>,
              <a href="https://scholar.google.com/citations?user=ocPXoIkAAAAJ&hl=en"> Jing Huang</a>,
              <a href="https://cs.stanford.edu/~jiaxuan/#1"> Jiaxuan You</a>,
              <a href="https://cs.stanford.edu/~jure/"> Jure Leskovec</a>
              <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
              <br>
              <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2021 
              <br>
              <a href="https://arxiv.org/abs/2009.09263">arXiv</a>
              /
              <a href="https://github.com/BinWang28/InductivE">code</a>
              <p></p>
              <p>A formal definition of inductive learnign on CKG is presented. We propose the first benchmark for inductive CKG completion task, including new data splits and testing schema, to facilitate future research.</p>
            </td>
        </tbody></table>
      <!-- Paper END -->

      <!-- Paper 9 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/sbertwk.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/9140343">
          <papertitle>SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word Models</papertitle>
          </a>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</em>, 2020 
          <br>
          <a href="https://arxiv.org/abs/2002.06652">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/abstract/document/9140343">IEEE</a>
          /
          <a href="https://github.com/BinWang28/SBERT-WK-Sentence-Embedding">code</a>
          <p></p>
          <p>We study the layer-wise pattern of the word representation of deep contextualized models. Then, we propose a new sentence embedding method by dissecting BERT-based word models through geometric analysis of the space spanned by the word representation.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->


      <!-- Paper 8 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/s3e.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2002.09620.pdf">
          <papertitle>Efficient Sentence Embedding via Semantic Subspace Analysis</papertitle>
          </a>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Pattern Recognition (ICPR)</em>, 2020 
          <br>
          <a href="https://arxiv.org/pdf/2002.09620.pdf">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/document/9412169">IEEE</a>
          /
          <a href="https://github.com/BinWang28/Sentence-Embedding-S3E">code</a>
          /
          <a href="https://www.youtube.com/watch?v=yEaX3eOOEiM">video</a>
          <p></p>
          <p>First, we represent words that lie in the same semantic group using the intra-group descriptor. Second, we characterize the interaction between multiple semantic groups with the inter-group descriptor.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 7 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/GRL.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/graph-representation-learning-a-survey/23B9870F91F7E6DA14784959A9BC9E7A">
          <papertitle>Graph Representation Learning: A Survey</papertitle>
          </a>
          <br>
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>APSIPA Transactions on Signal and Information Processing</em>, 2020 
          <br>
          <a href="https://arxiv.org/abs/1909.00958">arxiv</a>
          /
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/graph-representation-learning-a-survey/23B9870F91F7E6DA14784959A9BC9E7A">Cambridge</a>
          <p></p>
          <p>We first explain the graph embedding task and its challenges. Next, we review a wide range of graph embedding techniques with insights. Then, we evaluate several stat-of-the-art methods against small and large data sets and compare their performance.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 6 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/vecs.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79">
          <papertitle>Evaluating Word Embedding Models: Methods and Experimental Results</papertitle>
          </a>
          <br>
          <strong> Bin Wang*</strong>,
          <a href="https://www.researchgate.net/profile/Angela-Wang-15"> Angela Wang*</a>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>APSIPA Transactions on Signal and Information Processing</em>, 2019 
          <br>
          <a href="https://arxiv.org/abs/1901.09785">arxiv</a>
          /
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79">Cambridge</a>
          <p></p>
          <p>Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 5 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/we.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/document/8784743">
          <papertitle>Post-Processing of Word Representations via Variance Normalization and Dynamic Embedding</papertitle>
          </a>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://www.researchgate.net/profile/Angela-Wang-15"> Angela Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Multimedia & Expo (ICME)</em>, 2019 
          <br>
          <a href="https://arxiv.org/abs/1808.06305">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/document/8784743">IEEE</a>
          /
          <a href="https://github.com/BinWang28/PVN-Post-Processing-of-word-representation-via-variance-normalization">code</a>
          <p></p>
          <p>The PVN method normalizes the variance of principal components of word vectors, while the PDE method learns orthogonal latent variables from ordered input sequences. The PVN and the PDE methods can be integrated to achieve better performance.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 4 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/KCOVER.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/8794958">
          <papertitle>K-Covers for Active Learning in Image Classification</papertitle>
          </a>
          <br>
          <a href="https://scholar.google.com/citations?user=eFoaWFIAAAAJ&hl=en">Yeji Shen</a>,
          <a href="https://scholar.google.com/citations?user=PaPfxpoAAAAJ&hl=zh-CN"> Yuhang Song</a>,
          <a href="https://www.linkedin.com/in/li-hanhan-74495756/"> Hanhan Li</a>,
          <a href="https://www.linkedin.com/in/shahab-kamali-53029331/"> Shahab Kamali</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Multimedia & Expo Workshops (ICMEW)</em>, 2019 
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/8794958">IEEE</a>
          /
          <p></p>
          <p>K-Covers method to partition the feature space into several clusters and then choose one sample with the largest uncertainty in each cluster.</p>
        </td>
    </tbody></table>
  <!-- Paper END -->


      <!-- Paper 3 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/DGPCA.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/document/8682615">
          <papertitle>Deepwalk-assisted Graph PCA (DGPCA) for Language Networks</papertitle>
          </a>
          <br>
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/">Fenxiao Chen</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2019 
          <br>
          <a href="https://ieeexplore.ieee.org/document/8682615">IEEE</a>
          /
          <a href="https://www.researchgate.net/publication/332790194_Deepwalk-assisted_Graph_PCA_DGPCA_for_Language_Networks">Researchgate</a>
          <p></p>
          <p>A novel DeepWalk-assisted Graph PCA (DGPCA) method is proposed for processing language network data represented by graphs.</p>
        </td>
    </tbody></table>
  <!-- Paper END -->

      <!-- Paper 2 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/hand_gesture.png' width="160">
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://www.researchgate.net/publication/338315523_Hand_gesture_recognition_and_motion_estimation_using_the_Kinect_sensor">
            <papertitle>Hand gesture recognition and motion estimation using the Kinect sensor</papertitle>
            </a>
            <br>
            <strong>Bin Wang</strong>,
            <a> Yunze Li</a>,
            <a href="https://scholar.google.com/citations?user=GcttJ-oAAAAJ&hl=en"> Haoxiang Lang</a>,
            <a href="http://facultyweb.kennesaw.edu/ywang34/"> Ying Wang</a>
            <br>
            <em>Mechatronic Systems and Control</em>, 2020 
            <br>
            <a href="https://www.researchgate.net/publication/338315523_Hand_gesture_recognition_and_motion_estimation_using_the_Kinect_sensor">Researchgate</a>
            /
            <a href="https://www.youtube.com/watch?v=etjiZT4aRaQ">video demo1</a>
            /
            <a href="https://www.youtube.com/watch?v=qq9L5BcOeig">video demo2</a>
            <p></p>
            <p>Proposes and implements an efficient method to recognize hand gestures and estimate the motion of each fingertip using a combination of RGB image and depth image data acquired from Microsoft's Kinect sensor. The proposed approach can be widely applied to robotic applications, such as visual servoing and human-robot interactions.</p>
          </td>
      </tbody></table>
    <!-- Paper END -->

      <!-- Paper 1 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/DTRNN.png' width="160">
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/abstract/document/8639625">
            <papertitle>Graph-Based Deep-Tree Recursive Neural Network (DTRNN) for Text Classification</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/">Fenxiao Chen</a>,
            <strong> Bin Wang</strong>,
            <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
            <br>
            <em>IEEE Spoken Language Technology Workshop (SLT)</em>, 2018 
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/8639625">IEEE</a>
            /
            <a href="https://arxiv.org/abs/1809.01219">arXiv</a>
            <p></p>
            <p>A Deep-Tree Recursive Neural Network (DTRNN) method is presented and used to classify vertices that contains text data.</p>
          </td>
      </tbody></table>
    <!-- Paper END -->







      <!-- Service -->
        <table id="service" width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/viterbi.png' width="200">
            </td>
            <td width="75%" valign="center">
              <a href="data/syllabus-ee599-21sp-v3.pdf">Teaching Assistant, EE599, Spring 2021, USC</a>
              <br><br>
              <a href="data/SyllabusEE141L.pdf">Teaching Assistant, EE141L, Fall 2019, Fall 2020, USC</a>
              <br><br>
              <a href="data/EE155-syllabus-Spring20-ver3.pdf">Teaching Assistant, EE155L, Spring 2020, USC</a>
              <br><br>
              <a href="data/EE483syllabus2018.pdf">Teaching Assistant, EE483, Fall 2018, Spring 2019, USC</a>
            </td>
        </tbody></table>
      <!-- Service END-->


      <!-- fun_facts -->
        <table id="fun_facts" width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Fun Facts</heading>
              <p>1994 - 2013: I was born and raised in Jining, Shandong, China.</p>
              <p>2013 - 2017: Spend 4 wonderful years in Chengdu, Sichuan, China for my bachelor's study.</p>
              <p>2017 - 2021: Spend another 4 years in Los Angeles, California, US to obtain my PhD degree.</p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>


        </tbody></table>

      <!-- fun_facts END-->




      <!-- Last -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>

              <p align="center">
                <iframe width="300" height="225" src="https://datastudio.google.com/embed/reporting/cd664f77-242b-437e-ae26-240697a375eb/page/iMzIC" frameborder="0" style="border:0" allowfullscreen></iframe>
                </p>

              <p style="text-align:center;font-size:small;">
                Original HTML template taken from <a href="https://github.com/jonbarron/jonbarron_website">here</a>. Adapted by Bin with new functions including Navitation Bar & Visitor Statistics.
              </p>

              <p style="text-align:center;font-size:small;">
                Last Update: 05-30-2021
              </p>
              <br>


            </td>
          </tr>
        </tbody></table>
        
      
      </td>
    </tr>

  </table>



</body>

</html>
