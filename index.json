[{"authors":["admin"],"categories":null,"content":"I am Bin Wang, a third-year Ph.D. student in machine learning and natural language processing at USC. My advisor is C.-C. Jay Kuo.\nBefore coming to USC, I received his Bachelor’s degree in Electronic Information Engineering from University of Electronic Science and Technology of China (UESTC), Chengdu, China in June, 2017.\n","date":1570406400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1570406400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://binwang28.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am Bin Wang, a third-year Ph.D. student in machine learning and natural language processing at USC. My advisor is C.-C. Jay Kuo.\nBefore coming to USC, I received his Bachelor’s degree in Electronic Information Engineering from University of Electronic Science and Technology of China (UESTC), Chengdu, China in June, 2017.","tags":null,"title":"Bin Wang","type":"authors"},{"authors":["Bin Wang"],"categories":["Posts"],"content":" - Keep Track of Time Sometime, people get lot when there is a long-term goal. When we can not get feedback immediately when pouring our efforts,we are more likely to get lot. Give yourself some reward even when making small accomplishment.\n- More Responsibility Be responsible for your family, your friends, your students. But most importantly, you work for your own interest and future.\n- Self-Motivated You will never do a good job unless you like it.\n","date":1570406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570406400,"objectID":"a641fd1faf02c84fa2a077d3adc939d8","permalink":"https://binwang28.github.io/post/10-7-start_working/","publishdate":"2019-10-07T00:00:00Z","relpermalink":"/post/10-7-start_working/","section":"post","summary":"- Keep Track of Time Sometime, people get lot when there is a long-term goal. When we can not get feedback immediately when pouring our efforts,we are more likely to get lot. Give yourself some reward even when making small accomplishment.\n- More Responsibility Be responsible for your family, your friends, your students. But most importantly, you work for your own interest and future.\n- Self-Motivated You will never do a good job unless you like it.","tags":["Moments"],"title":"Several Bullets to keep in mind!","type":"post"},{"authors":["Bin Wang*","Angela Wang*","Fenxiao Chen","Yuncheng Wang","C.-C. Jay Kuo"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"2e9d71c8318879b8fb0a7747726adad9","permalink":"https://binwang28.github.io/publication/6-we_eval/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/publication/6-we_eval/","section":"publication","summary":"Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work. First, we introduce popular word embedding models and discuss desired properties of word models and evaluation methods (or evaluators). Then, we categorize evaluators into intrinsic and extrinsic two types. Intrinsic evaluators test the quality of a representation independent of specific natural language processing tasks while extrinsic evaluators use word embeddings as input features to a downstream task and measure changes in performance metrics specific to that task. We report experimental results of intrinsic and extrinsic evaluators on six word embedding models. It is shown that different evaluators focus on different aspects of word models, and some are more correlated with natural language processing tasks. Finally, we adopt correlation analysis to study performance consistency of extrinsic and intrinsic evalutors.","tags":["Word Embedding"],"title":"Evaluating Word Embedding Models: Methods and Experimental Results","type":"publication"},{"authors":[],"categories":null,"content":"","date":1562936400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562936400,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://binwang28.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"Presenting Papers","tags":[],"title":"ICME 2019","type":"talk"},{"authors":["Bin Wang","Fenxiao Chen","Angela Wang","C.-C. Jay Kuo"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"2d63339e2187d3f698754bad86ad43fb","permalink":"https://binwang28.github.io/publication/3-post-processing_word_em/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/3-post-processing_word_em/","section":"publication","summary":"Language processing becomes more and more important in multimedia processing. Although embedded vector representations of words offer impressive performance on many natural language processing (NLP) applications, the information of ordered input sequences is lost to some extent if only context-based samples are used in the training. For further performance improvement, two new post-processing techniques, called post-processing via variance normalization (PVN) and post-processing via dynamic embedding (PDE), are proposed in this work. The PVN method normalizes the variance of principal components of word vectors, while the PDE method learns orthogonal latent variables from ordered input sequences. The PVN and the PDE methods can be integrated to achieve better performance. We apply these post-processing techniques to several popular word embedding methods to yield their post-processed representations. Extensive experiments are conducted to demonstrate the effectiveness of the proposed post-processing techniques","tags":["Word Embedding"],"title":"Post-Processing of Word Representations via Variance Normalization and Dynamic Embedding","type":"publication"},{"authors":["Yeji Shen","Yuhang Song","Hanhan Li","Shahab Kamali","Bin Wang","C.-C. Jay Kuo"],"categories":null,"content":"","date":1561075200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561075200,"objectID":"3e654b525e8d77db2b9f40e9a529f5de","permalink":"https://binwang28.github.io/publication/5-k-cover/","publishdate":"2019-06-21T00:00:00Z","relpermalink":"/publication/5-k-cover/","section":"publication","summary":"Deep learning has shown its effectiveness in various computer vision tasks. However, a large amount of labeled data is usually needed for deep learning approaches. Active learning can help reduce the labeling efforts by choosing the most informative samples to label and thus achieves a comparable performance with less labeled data. In this paper, we argue that only choosing samples based on some uncertainty function would lead to an unbalanced distribution of the selected samples, especially when the initial set of labeled samples are unbalanced. Following the intuition of reducing the repetitive sampling for similar images, we propose a novel K-Covers method to partition the feature space into several clusters and then choose one sample with the largest uncertainty in each cluster. Our method can constantly outperform the state-ofthe-art with a clear margin.","tags":["Active Learning"],"title":"K-Covers for Active Learning in Image Classification","type":"publication"},{"authors":["Fenxiao Chen","Bin Wang","C.-C. Jay Kuo"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"920c8c06500f165b5cde4a254326349e","permalink":"https://binwang28.github.io/publication/4-dgpca/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/4-dgpca/","section":"publication","summary":"Language graph learning is an important task with many applications such as text classification, link prediction and community detection. One of the challenges in this domain is finding an efficient way to learn and encode graph into a low dimensional embedding. In this paper, a novel DeepWalk-assisted Graph PCA (DGPCA) method is proposed for processing language network data represented by graphs. This method can generate a precise text representation for nodes (or vertices) in language networks. Unlike other existing work, our learned low dimensional vector representations add flexibility in exploring vertices' neighborhood information, while reducing noise contained in the original data. To demonstrate the effectiveness, we use DGPCA to classify vertices that contain text information in three language networks. Experimentally, DGPCA is shown to perform well on the language datasets in comparison to several state-of-the-art benchmarking methods.","tags":["DeepWalk","Graph Embedding"],"title":"Deepwalk-assisted Graph PCA (DGPCA) for Language Networks","type":"publication"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://binwang28.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Fenxiao Chen","Bin Wang","C.-C. Jay Kuo"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"d9872f4ac10f744428864bf9aaa3038e","permalink":"https://binwang28.github.io/publication/1-graph-based-deep-tree/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/1-graph-based-deep-tree/","section":"publication","summary":"A novel graph-to-tree conversion mechanism called the deeptree generation (DTG) algorithm is first proposed to predict text data represented by graphs. The DTG method can generate a richer and more accurate representation for nodes (or vertices) in graphs. It adds flexibility in exploring the vertex neighborhood information to better reflect the second order proximity and homophily equivalence in a graph. Then, a Deep-Tree Recursive Neural Network (DTRNN) method is presented and used to classify vertices that contains text data in graphs. To demonstrate the effectiveness of the DTRNN method, we apply it to three real-world graph datasets and show that the DTRNN method outperforms several state-ofthe-art benchmarking methods.","tags":["RNN","Graph Node Classification"],"title":"Graph-based Deep-Tree Recursive Neural Network (DTRNN) for Text Classification","type":"publication"},{"authors":["Bin Wang","Yunze Li","Haoxiang Lang","Ying Wang"],"categories":null,"content":" This project is finished during my Intern at UOIT in 2016.\nVideo Demo 1 \nVideo Demo 2 \n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"120f47567b7f3874f569ee8f751dc6b1","permalink":"https://binwang28.github.io/publication/2-hand-gesture-recognition-and-motion-estimation-using-the-kinect-sensor/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2-hand-gesture-recognition-and-motion-estimation-using-the-kinect-sensor/","section":"publication","summary":"This paper proposes and implements an efficient method to recognize hand gestures and estimate the motion of each fingertip using a combination of RGB image and depth image data acquired from Microsoft’s Kinect sensor. The real-time performance of hand identification, tracking and motion estimation is achieved without any assistance of additional electronic devices. To guarantee the robust performance, differences between subsequent frames are analyzed and specific algorithms are utilized in the proposed system. In addition, the calibration using both focal length and angle range of the camera is applied to coordinate with different devices to obtain accurate speed estimation. The experiment results show the robust and real-time performance. The proposed approach can be widely applied to robotic applications such as visual servoing and human-robot interactions.","tags":["Hand Gesture","Kinect"],"title":"Hand gesture recognition and motion estimation using the Kinect Sensor","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://binwang28.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://binwang28.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]