<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Biography</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GQSE2H4QXE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GQSE2H4QXE');
</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Bin. Wang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
<div class="menu-item"><a href="biography.html" class="current">Biography</a></div>
<div class="menu-item"><a href="assets/data/Resume_Bin.pdf">CV</a></div>
<div class="menu-item"><a href="misc.html">Misc.</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="team.html">Team</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="teaching.html">Courses</a></div>
<div class="menu-category">Website</div>
<div class="menu-item"><a href="index_chinese.html">中文</a></div>
<div class="menu-item"><a href="statistics.html">Statistics</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Biography</h1>
</div>
<ul>
<li><p><i>05/2025 - Present</i>:  AI Research Scientist, MiroMind, Singapore
</p>
</li>
<li><p><i>04/2023 - 04/2025</i>:  Scientist, I2R, A*STAR, Singapore
</p>
</li>
<li><p><i>09/2021 - 03/2023</i>: Research Fellow, National University of Singapore
</p>
</li>
<li><p><i>08/2017 - 05/2021</i>: Ph.D. Student, University of Southern California, USA
</p>
</li>
<li><p><i>05/2020 - 08/2020</i>: Research Intern, JD AI Research, USA
</p>
</li>
<li><p><i>09/2013 - 07/2017</i>: Undergraduate Student, University of Electronic Science and Technology of China
</p>
</li>
<li><p><i>07/2016 - 10/2016</i>: Research Intern, Ontario Tech University, Canada
</p>
</li>
<li><p><i>08/2015 - 12/2015</i>: Exchange Student, City University of Hong Kong
</p>
</li>
<li><p><i>09/2010 - 07/2013</i>: Student, Jining No.1 High School, Shandong, China
</p>
</li>
</ul>
<h2>Awards</h2>
<ul>
<li><p>APSIPA Sadaoki Furui Prize Paper Award, 2024
</p>
</li>
<li><p>Best Paper Award - C3NLP Workshop, ACL 2024
</p>
</li>
<li><p>APSIPA Sadaoki Furui Prize Paper Award, 2022
</p>
</li>
<li><p>GSG Research Travel Grant, USC, 2019
</p>
</li>
<li><p>Excellent Graduate of Sichuan Province, 2017
</p>
</li>
<li><p>Undergraduate National Scholarship, China, 2016
</p>
</li>
<li><p>Tanglixin Scholarship, UESTC, 2016
</p>
</li>
<li><p>Undergraduate National Scholarship, China, 2015
</p>
</li>
<li><p>Samsung Undergraduate Scholarship, 2015
</p>
</li>
<li><p>Outstanding Student Leadership, UESTC, 2014
</p>
</li>
</ul>
<h2>Short Bio.</h2>
<p>Bin Wang is an AI Research Scientist at MiroMind, Singapore. He received his Ph.D. from the University of Southern California, Los Angeles in 2021 and B.Eng from the University of Electronic Science and Technology of China. He was a Research Fellow with the National University of Singapore from 2021 to 2023 and an AI scientist with the Institute for Infocomm Research (I2R, A*STAR, Singapore) from 2023 to 2025. His research focuses on Multimodal LLM and conversational AI systems. He served as the Publication Chair for EMNLP 2023 and an Editorial Member for APSIPA Transactions. He has published 40+ academic papers in top journals and conferences including ACL, EMNLP, NAACL, ACM KDD, TNNLS and TASLP, and has received multiple best paper awards.
</p>
<h2>About Me</h2>
<p>I am an AI Research Scientist at MiroMind, Singapore. Before that, I am a Scientist at Aural & Language Intelligence Department, I2R, A*STAR from 2023 to 2025 and a research fellow at National University of Singapore (<a href="https://www.nus.edu.sg/" target=&ldquo;blank&rdquo;>NUS</a>) working with Prof. <a href="https://colips.org/~eleliha/" target=&ldquo;blank&rdquo;>Haizhou Li</a> from 2021-2023. I received my Ph.D. degree from University of Southern California (<a href="https://www.usc.edu/" target=&ldquo;blank&rdquo;>USC</a>) supervised by Prof. <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh" target=&ldquo;blank&rdquo;>C.-C. Jay Kuo</a> in 2021. My bachelor's degree is obtained from University of Electronic Science and Technology of China (<a href="https://en.uestc.edu.cn/" target=&ldquo;blank&rdquo;>UESTC</a>) in 2017.
</p>
<h3>Some of the topics that I am currently researching include:</h3>
<ol>
<li><p><b>Make LLM can hear</b> - AudioLLM - Audio-Based Large Language Models
</p>
<ol>
<li><p>What techniques can be used to effectively integrate audio processing capabilities into existing LLM architectures? 
</p>
</li>
<li><p>What is the most efficient approach for achieving seamless cross-modality integration? 
</p>
</li>
<li><p>What benchmarks can be designed to accurately evaluate the real-world performance of AudioLLMs?
</p>
</li>
<li><p>Current Outcomes: <a href="https://huggingface.co/MERaLiON" target=&ldquo;blank&rdquo;>MERaLiON-AduioLLM</a>, <a href="https://github.com/AudioLLMs/AudioBench" target=&ldquo;blank&rdquo;>AudioBench</a>, <a href="https://github.com/AudioLLMs/Awesome-Audio-LLM" target=&ldquo;blank&rdquo;>Awesome-Audio-LLM</a>, <a href="https://arxiv.org/abs/2409.06635" target=&ldquo;blank&rdquo;>MoWE-Audio</a>
</p>
</li></ol>
</li>
<li><p><b>Multilingal and Multicultual LLM</b>
</p>
<ol>
<li><p>What unique properties should a multilingual LLM possess to cater to diverse languages effectively?
</p>
</li>
<li><p>How can multilingual learning be made more efficient and effective, especially for low-resource languages?
</p>
</li>
<li><p>What internal mechanisms can ensure robust multilingual knowledge alignment within the model?
</p>
</li>
<li><p>Current Outcomes: <a href="https://aclanthology.org/2024.naacl-long.22/" target=&ldquo;blank&rdquo;>SeaEval</a>, <a href="https://aclanthology.org/2024.c3nlp-1.4/" target=&ldquo;blank&rdquo;>CRAFT</a>, <a href="https://arxiv.org/abs/2404.11932" target=&ldquo;blank&rdquo;>CrossIn</a>, <a href="https://arxiv.org/abs/2406.10118" target=&ldquo;blank&rdquo;>SEACrowd</a>
</p>
</li></ol>
</li>
<li><p><b>Conversional AI</b>
</p>
<ol>
<li><p>Representation Learning for Retrieval-Augmented Generation, Knowledge Graphs
</p>
</li>
<li><p>What representation and coordination strategies can enhance multi-agent communication in shared environments?
</p>
</li>
<li><p>What methods can enable conversational agents to effectively reason and plan based on learned or provided world models?
</p>
</li>
<li><p>Current Outcomes: <a href="https://dl.acm.org/doi/abs/10.1109/TASLP.2020.3008390" target=&ldquo;blank&rdquo;>Representation Learning</a>, <a href="https://ieeexplore.ieee.org/document/9534355" target=&ldquo;blank&rdquo;>Commonsense Knowledge Graph</a>    
</p>
</li>
</ol>

</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2025-08-31 22:55:08 CST, by jemdoc+MathJax.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
