# jemdoc: menu{MENU}{index.html}, analytics{UA-144973743-1}
==Bin Wang

~~~
{}{img_left}{data/profile.png}{alt text}{210}{210}{https://binwang28.github.io/}
Name in Chinese: 王斌
\n
Research Fellow, PhD,
\n 
[https://cde.nus.edu.sg/ece/ Electrical and Computer Engineering],
\n
[https://www.nus.edu.sg/ National University of Singapore (NUS)]
\n
Address: \#06-20, Block E4, 4 Engineering Drive 3, Singapore 117583
\n
Phone: \+65 8439 0347
\n
Email: /bwang28c/ \[@\] gmail \[DOT\] com
\n
\[[https://scholar.google.com/citations?user=jUrRMv4AAAAJ&hl=en Google Scholar]]   
\[[https://github.com/BinWang28 GitHub]]   
\[[https://www.linkedin.com/in/bin-wang-3b7054140/ LinkedIn]]
\n\n
``/Produce original research that expands the boundaries of knowledge./''
~~~

== About me
I am currently a Research Fellow at National University of Singapore ([https://www.nus.edu.sg/ NUS]) - Human Language Technology ([https://cde.nus.edu.sg/ece/hlt/ HLT]) Lab working with Prof. [https://colips.org/~eleliha/ Haizhou Li]. 
\n
Before, I received my Ph.D. degree from University of Southern California ([https://www.usc.edu/ USC]) supervised by Prof. [https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh C.-C. Jay Kuo] in May, 2021.
\n
My bachelor's degree is obtained from University of Electronic Science and Technology of China ([https://en.uestc.edu.cn/ UESTC]) in 2017.

== News

- *Feb. 21, 2023*: Relational Sentence Embedding paper is out! Checkout our [https://arxiv.org/abs/2212.08802 paper] and [https://github.com/BinWang28/RSE code].
- *Nov. 08, 2022*: Our paper on word embedding won the [http://www.apsipa.org/awards.htm APSIPA Sadaoki Furui Prize Paper Award].
- *Oct. 20, 2022*: Two papers accepted to EMNLP main conference.
- *Mar. 18, 2022*: GraphHop paper is accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS).

== Research
My research interests focus on Conversational AI including but not limited to:
- Representation Learning for Words, Sentences and (Knowledge) Graphs
- Model and Evaluation on Dialogue Summarization
- Factual Consistency in Generation

[research.html Find out more].

== Call for Papers
- I am serving a Editorial Board for journal: [https://www.nowpublishers.com/SIP APSIPA Transactions on Signal and Information Processing] from year 2022 to 2025.
    -- Welcome to submit your manuscript to ATSIP.
    -- Some previous published papers have already attracted significant number of citations: [http://goo.gl/xWHRsf http://goo.gl/xWHRsf]

== Selected Publications 
. Bin Wang, Chen Zhang, Yan Zhang, Yiming Chen and Haizhou Li. "Analyzing and Evaluating Faithfulness in Dialogue Summarization." EMNLP, 2022. \[[https://arxiv.org/abs/2210.11777 paper]\], \[[https://github.com/BinWang28/FacEval code]\]
. Bin Wang, C.-C. Jay Kuo, and Haizhou Li. "Just Rank: Rethinking Evaluation with Word and Sentence Similarities." ACL, 2022. \[[https://arxiv.org/abs/2203.02679 paper]\], \[[https://github.com/BinWang28/EvalRank-Embedding-Evaluation code]\]
. Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, and C.-C. Jay Kuo. "Inductive learning on commonsense knowledge graph completion." IJCNN, 2021. \[[https://arxiv.org/abs/2009.09263 paper]\], \[[https://github.com/BinWang28/InductivE code]\]
. Bin Wang, and C.-C. Jay Kuo. "SBERT-WK: A sentence embedding method by dissecting bert-based word models." IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. \[[https://ieeexplore.ieee.org/document/9140343 paper]\], \[[https://github.com/BinWang28/SBERT-WK-Sentence-Embedding code]\]
. Bin Wang\*, Angela Wang\*, Fenxiao Chen, Yuncheng Wang, and C.-C. Jay Kuo. "Evaluating word embedding models: methods and experimental results." APSIPA transactions on signal and information processing, 2019. \[[https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79 paper]\], \[[https://github.com/BinWang28/Word-Embedding-Eval code]\]

[publications.html Full list of publications].