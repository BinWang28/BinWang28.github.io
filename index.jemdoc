# jemdoc: menu{MENU}{index.html}, analytics{|}

== Bin Wang

~~~
{}{img_left}{data/profile.png}{alt text}{210}{210}{https://binwang.xyz/}
Scientist
\n
Institute for Infocomm Research [https://www.a-star.edu.sg/i2r (I$^2$R)], [https://www.a-star.edu.sg A\*STAR], Singapore
\n
Address: 1 Fusionopolis Way, Level 12, Connexis South Tower, Singapore 138632
\n
Personal Email: /bwang28c/ \[@\] gmail.com 
\n
Work Email: wang_bin / \[@\] i2r.a-star.edu.sg
\n
\[[https://scholar.google.com/citations?user=jUrRMv4AAAAJ&hl=en Google Scholar]]~~~
\[[https://github.com/BinWang28 GitHub]]~~~
\[[https://huggingface.co/binwang HuggingFace]]~~~
\[[https://www.linkedin.com/in/bin-wang-3b7054140/ LinkedIn]]~~~
\[[https://twitter.com/BinWang_Eng Twitter]]
~~~

== News
- 2025.01~Our AudioBench work is officially accepted to NAACL 2025 Main Conference! [https://huggingface.co/spaces/MERaLiON/AudioBench-Leaderboard Leaderboard] and [https://github.com/AudioLLMs/AudioBench Code].
- 2024.12~We released [https://huggingface.co/MERaLiON MERaLiON models], the first audio-based large language model designed specifically for Singlish and other related tasks!
- 2024-2026~Our team is working on National LLM Project [https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2023/sg-to-develop-southeast-asias-first-llm-ecosystem Press Coverage].
- 2024~AudioBench is released with leaderboard and evaluation toolkit - [https://arxiv.org/abs/2406.16020 AudioLLM Evaluation].
- 2024~NAACL [https://seaeval.github.io/ SeaEval for Multilingual Evaluation].

== About Me
I am a scientist at Aural \& Language Intelligence Department, I2R, A\*STAR. Before joing that, I was a research fellow at National University of Singapore ([https://www.nus.edu.sg/ NUS]) working with Prof. [https://colips.org/~eleliha/ Haizhou Li] from 2021-2023. I received my Ph.D. degree from University of Southern California ([https://www.usc.edu/ USC]) supervised by Prof. [https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh C.-C. Jay Kuo] in 2021. My bachelor's degree is obtained from University of Electronic Science and Technology of China ([https://en.uestc.edu.cn/ UESTC]) in 2017.

=== Some of the topics that I am currently researching include:
. *Make LLM can hear* - AudioLLM - Audio-Based Large Language Models
    .. What techniques can be used to effectively integrate audio processing capabilities into existing LLM architectures? 
    .. What is the most efficient approach for achieving seamless cross-modality integration? 
    .. What benchmarks can be designed to accurately evaluate the real-world performance of AudioLLMs?
    .. Current Outcomes: [https://huggingface.co/MERaLiON MERaLiON-AduioLLM], [https://github.com/AudioLLMs/AudioBench AudioBench], [https://github.com/AudioLLMs/Awesome-Audio-LLM Awesome-Audio-LLM], [https://arxiv.org/abs/2409.06635 MoWE-Audio]
. *Multilingal and Multicultual LLM*
    .. What unique properties should a multilingual LLM possess to cater to diverse languages effectively?
    .. How can multilingual learning be made more efficient and effective, especially for low-resource languages?
    .. What internal mechanisms can ensure robust multilingual knowledge alignment within the model?
    .. Current Outcomes: [https://aclanthology.org/2024.naacl-long.22/ SeaEval], [https://aclanthology.org/2024.c3nlp-1.4/ CRAFT], [https://arxiv.org/abs/2404.11932 CrossIn], [https://arxiv.org/abs/2406.10118 SEACrowd]
. *Conversional AI*
    .. Representation Learning for Retrieval-Augmented Generation, Knowledge Graphs
    .. What representation and coordination strategies can enhance multi-agent communication in shared environments?
    .. What methods can enable conversational agents to effectively reason and plan based on learned or provided world models?
    .. Current Outcomes: [https://dl.acm.org/doi/abs/10.1109/TASLP.2020.3008390 Representation Learning], [https://ieeexplore.ieee.org/document/9534355 Commonsense Knowledge Graph]    

== Opportunities

~~~
We are actively looking for candidates working on Multimodal LLMs (text, audio, vision, etc.).
\n
- Research Interns (6 months or above preferred), 
\n
-- [https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-sipga SIPGA] for international (master / undergraduate) students.
-- [https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/a-star-research-internship-award-aria ARIA] for Singaporean undergraduate students.
-- [https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme ARAP] for international Ph.D. students attachment for 1-2 years.
-- Local students from NUS, NTU, SMU, SUTD, SIT, Polytechnic etc. please contact me directly for attachment to projects.
\n
- Ph.D. Students
\n
-- [https://www.a-star.edu.sg/Scholarships/for-graduate-studies SIPGA, AGS, ACIS]
\n
- Long-term Positions
-- Research Engineer / Scientist (Both engineering and research background are preferred.)
~~~


== Some Publications 
. Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen. "AudioBench: A Universal Benchmark for Audio Large Language Models." NAACL, 2025. \[[https://arxiv.org/abs/2406.16020 paper]\], \[[https://github.com/AudioLLMs/AudioBench code]\]
. Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, Nancy F. Chen. "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning." NAACL, 2024. \[[https://aclanthology.org/2024.naacl-long.22/ paper]\], \[[https://github.com/SeaEval/SeaEval code]\]
. Bin Wang, Chen Zhang, Yan Zhang, Yiming Chen and Haizhou Li. "Analyzing and Evaluating Faithfulness in Dialogue Summarization." EMNLP, 2022. \[[https://arxiv.org/abs/2210.11777 paper]\], \[[https://github.com/BinWang28/FacEval code]\]
. Bin Wang, C.-C. Jay Kuo, and Haizhou Li. "Just Rank: Rethinking Evaluation with Word and Sentence Similarities." ACL, 2022. \[[https://arxiv.org/abs/2203.02679 paper]\], \[[https://github.com/BinWang28/EvalRank-Embedding-Evaluation code]\]
. Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, and C.-C. Jay Kuo. "Inductive learning on commonsense knowledge graph completion." IJCNN, 2021. \[[https://arxiv.org/abs/2009.09263 paper]\], \[[https://github.com/BinWang28/InductivE code]\]
. Bin Wang, and C.-C. Jay Kuo. "SBERT-WK: A sentence embedding method by dissecting bert-based word models." IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. \[[https://ieeexplore.ieee.org/document/9140343 paper]\], \[[https://github.com/BinWang28/SBERT-WK-Sentence-Embedding code]\]
. Bin Wang\*, Angela Wang\*, Fenxiao Chen, Yuncheng Wang, and C.-C. Jay Kuo. "Evaluating word embedding models: methods and experimental results." APSIPA transactions on signal and information processing, 2019. \[[https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79 paper]\], \[[https://github.com/BinWang28/Word-Embedding-Eval code]\]

[publications.html Full list of publications].

