# jemdoc: menu{MENU}{index.html}, analytics{|}

== Bin Wang

~~~
{}{img_left}{data/profile.png}{alt text}{210}{210}{https://binwang.xyz/}
AI Research Scientist
\n
MiroMind, Singapore
\n
Email: bwang28c@gmail.com / bin.wang@miromind.ai
\n \n
\[[https://scholar.google.com/citations?user=jUrRMv4AAAAJ&hl=en Google Scholar]]~
\[[https://github.com/BinWang28 GitHub]]~
\[[https://huggingface.co/binwang HuggingFace]]~
\n
\[[https://www.linkedin.com/in/bin-wang-3b7054140/ LinkedIn]]~
\[[https://twitter.com/BinWang_Eng Twitter]]~
\[[https://www.xiaohongshu.com/user/profile/5d61c7420000000001006c44 RedNote]]~
~~~

== Opportunities

*We are actively seeking talented Interns (paid) and Full-Time researchers to join MiroMind. Positions available in Singapore, Beijing, and Shanghai.*
\n
Interested candidates are welcome to reach out via email.

== News
- 2025.05~We published a comprehensive survey paper titled "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models" [https://arxiv.org/abs/2505.00551 arXiv].
- 2025.03~A talk on AudioLLM evaluation will be given at Lorong AI. Check out the slides [data/AudioBench_for_Lorong_AI.pdf here].
- 2025.03~I will be joining Shanda AI Research Institute (SARI) as an AI Research Scientist working on LLMs in May. I will still based in Singapore and open for collaboration opportunities.
- 2025.01~Our AudioBench work is officially accepted to NAACL 2025 Main Conference! [https://huggingface.co/spaces/MERaLiON/AudioBench-Leaderboard Leaderboard] and [https://github.com/AudioLLMs/AudioBench Code].
- 2024.12~We released [https://huggingface.co/MERaLiON MERaLiON models], the first audio-based large language model designed specifically for Singlish and other related tasks!
- 2024-2026~Our team is working on National LLM Project [https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2023/sg-to-develop-southeast-asias-first-llm-ecosystem Press Coverage].
- 2024~AudioBench is released with leaderboard and evaluation toolkit - [https://arxiv.org/abs/2406.16020 AudioLLM Evaluation].
- 2024~NAACL [https://seaeval.github.io/ SeaEval for Multilingual Evaluation].

== About Me
I am an AI Research Scientist at MiroMind, Singapore. Before that, I am a Scientist at Aural \& Language Intelligence Department, I2R, A\*STAR from 2023 to 2025 and a research fellow at National University of Singapore ([https://www.nus.edu.sg/ NUS]) working with Prof. [https://colips.org/~eleliha/ Haizhou Li] from 2021-2023. I received my Ph.D. degree from University of Southern California ([https://www.usc.edu/ USC]) supervised by Prof. [https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh C.-C. Jay Kuo] in 2021. My bachelor's degree is obtained from University of Electronic Science and Technology of China ([https://en.uestc.edu.cn/ UESTC]) in 2017.

=== Some of the topics that I am currently researching include:
. *Make LLM can hear* - AudioLLM - Audio-Based Large Language Models
    .. What techniques can be used to effectively integrate audio processing capabilities into existing LLM architectures? 
    .. What is the most efficient approach for achieving seamless cross-modality integration? 
    .. What benchmarks can be designed to accurately evaluate the real-world performance of AudioLLMs?
    .. Current Outcomes: [https://huggingface.co/MERaLiON MERaLiON-AduioLLM], [https://github.com/AudioLLMs/AudioBench AudioBench], [https://github.com/AudioLLMs/Awesome-Audio-LLM Awesome-Audio-LLM], [https://arxiv.org/abs/2409.06635 MoWE-Audio]
. *Multilingal and Multicultual LLM*
    .. What unique properties should a multilingual LLM possess to cater to diverse languages effectively?
    .. How can multilingual learning be made more efficient and effective, especially for low-resource languages?
    .. What internal mechanisms can ensure robust multilingual knowledge alignment within the model?
    .. Current Outcomes: [https://aclanthology.org/2024.naacl-long.22/ SeaEval], [https://aclanthology.org/2024.c3nlp-1.4/ CRAFT], [https://arxiv.org/abs/2404.11932 CrossIn], [https://arxiv.org/abs/2406.10118 SEACrowd]
. *Conversional AI*
    .. Representation Learning for Retrieval-Augmented Generation, Knowledge Graphs
    .. What representation and coordination strategies can enhance multi-agent communication in shared environments?
    .. What methods can enable conversational agents to effectively reason and plan based on learned or provided world models?
    .. Current Outcomes: [https://dl.acm.org/doi/abs/10.1109/TASLP.2020.3008390 Representation Learning], [https://ieeexplore.ieee.org/document/9534355 Commonsense Knowledge Graph]    


== Some Publications 
. Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen. "AudioBench: A Universal Benchmark for Audio Large Language Models." NAACL, 2025. \[[https://arxiv.org/abs/2406.16020 paper]\], \[[https://github.com/AudioLLMs/AudioBench code]\]
. Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, Nancy F. Chen. "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning." NAACL, 2024. \[[https://aclanthology.org/2024.naacl-long.22/ paper]\], \[[https://github.com/SeaEval/SeaEval code]\]
. Bin Wang, Chen Zhang, Yan Zhang, Yiming Chen and Haizhou Li. "Analyzing and Evaluating Faithfulness in Dialogue Summarization." EMNLP, 2022. \[[https://arxiv.org/abs/2210.11777 paper]\], \[[https://github.com/BinWang28/FacEval code]\]
. Bin Wang, C.-C. Jay Kuo, and Haizhou Li. "Just Rank: Rethinking Evaluation with Word and Sentence Similarities." ACL, 2022. \[[https://arxiv.org/abs/2203.02679 paper]\], \[[https://github.com/BinWang28/EvalRank-Embedding-Evaluation code]\]
. Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, and C.-C. Jay Kuo. "Inductive learning on commonsense knowledge graph completion." IJCNN, 2021. \[[https://arxiv.org/abs/2009.09263 paper]\], \[[https://github.com/BinWang28/InductivE code]\]
. Bin Wang, and C.-C. Jay Kuo. "SBERT-WK: A sentence embedding method by dissecting bert-based word models." IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. \[[https://ieeexplore.ieee.org/document/9140343 paper]\], \[[https://github.com/BinWang28/SBERT-WK-Sentence-Embedding code]\]
. Bin Wang\*, Angela Wang\*, Fenxiao Chen, Yuncheng Wang, and C.-C. Jay Kuo. "Evaluating word embedding models: methods and experimental results." APSIPA transactions on signal and information processing, 2019. \[[https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79 paper]\], \[[https://github.com/BinWang28/Word-Embedding-Eval code]\]

[publications.html Full list of publications].

