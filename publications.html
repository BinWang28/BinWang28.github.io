<!DOCTYPE HTML>
<html lang="en">
  
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Bin Wang - Publications</title>
  
  <meta name="author" content="Bin Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/page_icon.png">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-144973743-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-144973743-1');
  </script>


</head>



<body>
  

  <!-- NEVIGATION BAR -->
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        
        <p style="text-align:left; color:#f7f7f7">
          <div class="topnav">
            <a href="index.html">Home</a>
            <a href="education.html">Edu. and Work Expe.</a>
            <a href="publications.html" class="active">Publications</a>
            <a href="services.html">Services</a>
          </div>
        </p>
  <!-- = = = = = = = = = = -->

        <br>  


  <!-- PROFILE PAGE -->
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#283747"><tbody>
    <tr style="padding:0px">

      <td style="padding:2.5%;width:63%;vertical-align:middle;color:#f7f7f7">

        <p style="text-align:left; color:#f7f7f7">
          <name>Bin Wang (王斌) </name> 
        </p>

        <p>
          Bin Wang is currently a Research Fellow at National University of Singapore (NUS) - <a href="https://www.eng.nus.edu.sg/ece/hlt/" style="color:rgb(0, 166, 255)"> Human Language Technology (HLT) Lab </a>.
          <br>
          He receives his Ph.D. degree from University of Southern California (USC) under the supervision of <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh" style="color:rgb(0, 166, 255)"> Prof. C.-C. Jay Kuo </a> in 2021 and his B.Eng degree from University of Electronic Science and Technology of China (UESTC) in 2017. 
        </p>

        <p style="text-align:center">
          <a href="mailto:bwang28c@gmail.com" style="color:rgb(0, 166, 255)">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=jUrRMv4AAAAJ&hl=en" style="color:rgb(0, 166, 255)">Google Scholar</a> &nbsp/&nbsp
          <a href="data/Bin-CV.pdf" style="color:rgb(0, 166, 255)">CV</a> &nbsp/&nbsp
          <a href="https://github.com/BinWang28" style="color:rgb(0, 166, 255)">Github</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/bin-wang-3b7054140/" style="color:rgb(0, 166, 255)">LinkedIn</a>

        </p>

      </td>

      <td style="padding:2.5%;width:25%;max-width:25%">
        <a><img style="width:100%;max-width:100%" alt="profile photo" src="images/page_bin.png" class="hoverZoomLink"></a>
      </td>

    </tr>
    </tbody>
  </table>
<!-- = = = = = = = = = = -->


        <p style="text-align:left; color:#f7f7f7">
          <div class="topnav">
            <a href="#2021">2021</a>
            <a href="#2020">2020</a>
            <a href="#2019">2019</a>
            <a href="#2018">2018</a>
          </div>
        </p>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#283747"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle;color:#f7f7f7">
            </td>
          </tr>
          </tbody>
        </table>

        Best papers of the year are <span class="highlight">highlighted</span>. <br>
        * indicates equal contribution.


      <!-- = = = = = = = = = = YEAR 2021 = = = = = = = = = = -->
      <table id='2021' style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Year - 2021</heading>
          </td>
        </tr>
      </tbody></table>


      <!-- Paper 15 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/pedenet.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>PEDENet: Image Anomaly Localization via Patch Embedding and Density Estimation</papertitle>
          <br>
          <a href="https://scholar.google.com/citations?user=yCX2_n4AAAAJ&hl=en"> Kaitai Zhang</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>Pattern Recognition Letter</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2110.15525">arxiv</a>
          <p></p>
          <p> PEDENet is targeting on learn feature with clustering effects to distinguish anomaly. PEDENet contains a patch embedding (PE) network, a density estimation (DE) network, and a location prediction (LP) network.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->



      <!-- Paper 14 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/cedwe.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Task-Specific Dependency-based Word Embedding Methods</papertitle>
          <br>
          <a href="https://www.linkedin.com/in/chengwei-wei-23675a1b3/"> Chengwei Wei</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>Preprint</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2110.13376">arxiv</a>
          <p></p>
          <p>A matrix factorization approach for word embedding by taking syntactic parsing in to consideration and enhanced by class-specific information.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->


      <!-- Paper 13 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/anomalyhop.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>AnomalyHop: An SSL-based Image Anomaly Localization Method</papertitle>
          <br>
          <a href="https://scholar.google.com/citations?user=yCX2_n4AAAAJ&hl=en"> Kaitai Zhang*</a>,
          <strong> Bin Wang*</strong>,
          <a href="https://www.linkedin.com/in/weiwang16/"> Wei Wang</a>,
          <a href="https://scholar.google.com/citations?user=YxnQx40AAAAJ&hl=en"> Fahad Sohrab</a>,
          <a href="https://scholar.google.com/citations?user=cHukfSUAAAAJ&hl=en"> Moncef Gabbouj</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>IEEE Visual Communications and Image Processing (VCIP)</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2105.03797">arxiv</a>
          /
          <a href="https://github.com/BinWang28/AnomalyHop">code</a>
          <p></p>
          <p>Comparing with state-of-the-art image anomaly localization methods based on deep neural networks (DNNs), AnomalyHop is mathematically transparent, easy to train, and fast in its inference speed.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 12 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/dt.gif' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Dynamic Texture Synthesis by Incorporating Long-range Spatial and Temporal Correlations</papertitle>
          <br>
          <a href="https://scholar.google.com/citations?user=yCX2_n4AAAAJ&hl=en"> Kaitai Zhang</a>,
          <strong> Bin Wang</strong>,
          <a href="https://scholar.google.com/citations?user=uWIBdm8AAAAJ&hl=en"> Hong-Shuo Chen</a>,
          <a href="https://scholar.google.com/citations?user=9el0ufkAAAAJ&hl=en"> Ye Wang</a>,
          <a href="https://www.linkedin.com/in/shiyu-mou-110623ba/"> Shiyu Mou</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Symposium on Signals, Circuits and Systems (ISSCS) </em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2104.05940">arxiv</a>
          /
          <p></p>
          <p>Maintain spatial and temporal consistency in synthesized dynamic textures. We incorporate a new loss term, called the Shifted Gram loss, to capture the structural and long-range correlation of the reference texture video.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 11 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/graphhop.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>GraphHop: An Enhanced Label Propagation Method for Node Classification</papertitle>
          <br>
          <a href="https://scholar.google.com/citations?user=wKjXhH8AAAAJ&hl=en&oi=sra"> Tian Xie</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>Preprint</em>, 2021 
          <br>
          <a href="https://arxiv.org/abs/2101.02326">arxiv</a>
          /
          <a href="https://github.com/TianXieUSC/GraphHop">code</a>
          <p></p>
          <p>With proper initial label vector embeddings, each iteration of GraphHop contains two steps: 1) label aggregation and 2) label update. The iterative procedure exploits the neighborhood information and enables GraphHop to perform well in an extremely small label rate setting and scale well for very large graphs.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 10 -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="inductive_stop()" onmouseover="inductive_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inductive_image'><video  width=100% height=100% muted autoplay loop>
                  <img src='images/inductive-memo.jpg' width="160"></div>
                  <img src='images/inductive-memo.jpg' width="160">
                </div>
              <script type="text/javascript">
                function inductive_start() {
                  document.getElementById('inductive_image').style.opacity = "1";
                }

                function inductive_stop() {
                  document.getElementById('inductive_image').style.opacity = "0";
                }
                inductive_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Inductive Learning on Commonsense Knowledge Graph Completion</papertitle>
              <br>
              <strong>Bin Wang</strong>,
              <a href="https://scholar.google.com/citations?user=ga5aRGkAAAAJ&hl=en"> Guangtao Wang</a>,
              <a href="https://scholar.google.com/citations?user=ocPXoIkAAAAJ&hl=en"> Jing Huang</a>,
              <a href="https://cs.stanford.edu/~jiaxuan/#1"> Jiaxuan You</a>,
              <a href="https://cs.stanford.edu/~jure/"> Jure Leskovec</a>
              <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
              <br>
              <em>International Joint Conference on Neural Networks (IJCNN)</em>, 2021 
              <br>
              <a href="https://arxiv.org/abs/2009.09263">arXiv</a>
              /
              <a href="https://github.com/BinWang28/InductivE">code</a>
              <p></p>
              <p>A formal definition of inductive learnign on CKG is presented. We propose the first benchmark for inductive CKG completion task, including new data splits and testing schema, to facilitate future research.</p>
            </td>
        </tbody></table>
      <!-- Paper END -->


      <!-- = = = = = = = = = = YEAR 2020 = = = = = = = = = = -->
      <table id='2020' style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Year - 2020</heading>
        </td>
      </tr>
      </tbody></table>


      <!-- Paper 9 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/sbertwk.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word Models</papertitle>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)</em>, 2020 
          <br>
          <a href="https://arxiv.org/abs/2002.06652">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/abstract/document/9140343">IEEE</a>
          /
          <a href="https://github.com/BinWang28/SBERT-WK-Sentence-Embedding">code</a>
          <p></p>
          <p>We study the layer-wise pattern of the word representation of deep contextualized models. Then, we propose a new sentence embedding method by dissecting BERT-based word models through geometric analysis of the space spanned by the word representation.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->


      <!-- Paper 8 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/s3e.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Efficient Sentence Embedding via Semantic Subspace Analysis</papertitle>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Pattern Recognition (ICPR)</em>, 2020 
          <br>
          <a href="https://arxiv.org/pdf/2002.09620.pdf">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/document/9412169">IEEE</a>
          /
          <a href="https://github.com/BinWang28/Sentence-Embedding-S3E">code</a>
          /
          <a href="https://www.youtube.com/watch?v=yEaX3eOOEiM">video</a>
          <p></p>
          <p>First, we represent words that lie in the same semantic group using the intra-group descriptor. Second, we characterize the interaction between multiple semantic groups with the inter-group descriptor.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 7 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/GRL.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Graph Representation Learning: A Survey</papertitle>
          <br>
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>APSIPA Transactions on Signal and Information Processing</em>, 2020 
          <br>
          <a href="https://arxiv.org/abs/1909.00958">arxiv</a>
          /
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/graph-representation-learning-a-survey/23B9870F91F7E6DA14784959A9BC9E7A">Cambridge</a>
          <p></p>
          <p>We first explain the graph embedding task and its challenges. Next, we review a wide range of graph embedding techniques with insights. Then, we evaluate several stat-of-the-art methods against small and large data sets and compare their performance.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->


      <!-- Paper 2 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/hand_gesture.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Hand gesture recognition and motion estimation using the Kinect sensor</papertitle>
          <br>
          <strong>Bin Wang</strong>,
          <a> Yunze Li</a>,
          <a href="https://scholar.google.com/citations?user=GcttJ-oAAAAJ&hl=en"> Haoxiang Lang</a>,
          <a href="http://facultyweb.kennesaw.edu/ywang34/"> Ying Wang</a>
          <br>
          <em>Mechatronic Systems and Control</em>, 2020 
          <br>
          <a href="https://www.researchgate.net/publication/338315523_Hand_gesture_recognition_and_motion_estimation_using_the_Kinect_sensor">Researchgate</a>
          /
          <a href="https://www.youtube.com/watch?v=etjiZT4aRaQ">video demo1</a>
          /
          <a href="https://www.youtube.com/watch?v=qq9L5BcOeig">video demo2</a>
          <p></p>
          <p>Proposes and implements an efficient method to recognize hand gestures and estimate the motion of each fingertip using a combination of RGB image and depth image data acquired from Microsoft's Kinect sensor. The proposed approach can be widely applied to robotic applications, such as visual servoing and human-robot interactions.</p>
        </td>
    </tbody></table>
  <!-- Paper END -->


      <!-- = = = = = = = = = = YEAR 2019 = = = = = = = = = = -->
      <table id='2019' style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Year - 2019</heading>
        </td>
      </tr>
      </tbody></table>


      <!-- Paper 6 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" bgcolor="#ffffd0" ><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/vecs.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Evaluating Word Embedding Models: Methods and Experimental Results</papertitle>
          <br>
          <strong> Bin Wang*</strong>,
          <a href="https://www.researchgate.net/profile/Angela-Wang-15"> Angela Wang*</a>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://scholar.google.com/citations?user=1qCEtO4AAAAJ&hl=zh-TW"> Yun-Cheng Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>APSIPA Transactions on Signal and Information Processing</em>, 2019 
          <br>
          <a href="https://arxiv.org/abs/1901.09785">arxiv</a>
          /
          <a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79">Cambridge</a>
          <p></p>
          <p>Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 5 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/we.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Post-Processing of Word Representations via Variance Normalization and Dynamic Embedding</papertitle>
          <br>
          <strong> Bin Wang</strong>,
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/"> Fenxiao Chen</a>,
          <a href="https://www.researchgate.net/profile/Angela-Wang-15"> Angela Wang</a>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Multimedia & Expo (ICME)</em>, 2019 
          <br>
          <a href="https://arxiv.org/abs/1808.06305">arxiv</a>
          /
          <a href="https://ieeexplore.ieee.org/document/8784743">IEEE</a>
          /
          <a href="https://github.com/BinWang28/PVN-Post-Processing-of-word-representation-via-variance-normalization">code</a>
          <p></p>
          <p>The PVN method normalizes the variance of principal components of word vectors, while the PDE method learns orthogonal latent variables from ordered input sequences. The PVN and the PDE methods can be integrated to achieve better performance.</p>
        </td>
    </tbody></table>
      <!-- Paper END -->

      <!-- Paper 4 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/KCOVER.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>K-Covers for Active Learning in Image Classification</papertitle>
          <br>
          <a href="https://scholar.google.com/citations?user=eFoaWFIAAAAJ&hl=en">Yeji Shen</a>,
          <a href="https://scholar.google.com/citations?user=PaPfxpoAAAAJ&hl=zh-CN"> Yuhang Song</a>,
          <a href="https://www.linkedin.com/in/li-hanhan-74495756/"> Hanhan Li</a>,
          <a href="https://www.linkedin.com/in/shahab-kamali-53029331/"> Shahab Kamali</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Multimedia & Expo Workshops (ICMEW)</em>, 2019 
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/8794958">IEEE</a>
          /
          <p></p>
          <p>K-Covers method to partition the feature space into several clusters and then choose one sample with the largest uncertainty in each cluster.</p>
        </td>
    </tbody></table>
  <!-- Paper END -->


      <!-- Paper 3 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
              <img src='images/DGPCA.png' width="160">
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Deepwalk-assisted Graph PCA (DGPCA) for Language Networks</papertitle>
          <br>
          <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/">Fenxiao Chen</a>,
          <strong> Bin Wang</strong>,
          <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
          <br>
          <em>International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2019 
          <br>
          <a href="https://ieeexplore.ieee.org/document/8682615">IEEE</a>
          /
          <a href="https://www.researchgate.net/publication/332790194_Deepwalk-assisted_Graph_PCA_DGPCA_for_Language_Networks">Researchgate</a>
          <p></p>
          <p>A novel DeepWalk-assisted Graph PCA (DGPCA) method is proposed for processing language network data represented by graphs.</p>
        </td>
    </tbody></table>
  <!-- Paper END -->



      <!-- = = = = = = = = = = YEAR 2018 = = = = = = = = = = -->
      <table id='2018' style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" ><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Year - 2018</heading>
        </td>
      </tr>
      </tbody></table>



      <!-- Paper 1 -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
                <img src='images/DTRNN.png' width="160">
              </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Graph-Based Deep-Tree Recursive Neural Network (DTRNN) for Text Classification</papertitle>
            <br>
            <a href="https://www.linkedin.com/in/jessica-fenxiao-chen-2b38a269/">Fenxiao Chen</a>,
            <strong> Bin Wang</strong>,
            <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh"> C.-C. Jay Kuo</a>
            <br>
            <em>IEEE Spoken Language Technology Workshop (SLT)</em>, 2018 
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/8639625">IEEE</a>
            /
            <a href="https://arxiv.org/abs/1809.01219">arXiv</a>
            <p></p>
            <p>A Deep-Tree Recursive Neural Network (DTRNN) method is presented and used to classify vertices that contains text data.</p>
          </td>
      </tbody></table>
    <!-- Paper END -->




        
      
      </td>
    </tr>

  </table>



</body>

</html>
