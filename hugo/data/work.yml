miromind:
  position: "AI Research Scientist"
  period: "05/2025 - Present"
  location: "MiroMind, Singapore"
  current: true
  research_section:
    topics_summary: "I joined MiroMind as an AI Research Scientist to work on the frontiers of large language models, multimodal AI systems, and agentic frameworks. My focus is on building practical AI solutions that push the boundaries of reasoning and intelligence."
    research_topics:
      - title: "Agentic AI & Reasoning Models"
        questions:
          - "How can we build AI agents that reason effectively and interact with complex environments?"
          - "What architectures enable robust multi-step reasoning in LLMs?"
    projects:
      - name: "MiroFlow"
        url: "https://github.com/MiroMindAI/MiroFlow"
        description: "Agent framework developed at MiroMind (1.8k GitHub stars)"
      - name: "MiroThinker"
        url: "https://github.com/MiroMindAI/MiroThinker"
        description: "Agentic model developed at MiroMind (1.5k GitHub stars)"
      - name: "MiroMind-M1"
        url: "https://github.com/MiroMindAI/MiroMind-M1"
        description: "Foundation reasoning model developed at MiroMind"
    publications:
      - name: "MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling"
        url: "https://arxiv.org/abs/2511.11793"
        venue: "Technical Report 2025"
      - name: "MiroFlow: Towards High-Performance, Robust, and Open-Source Reproducible Agent Framework for General Research"
        venue: "Technical Report 2025"
      - name: "MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization"
        url: "https://arxiv.org/abs/2507.14683"
        venue: "Technical Report 2025"
      - name: "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models"
        url: "https://arxiv.org/abs/2505.00551"
        venue: "Technical Review 2025"

i2r:
  position: "Scientist"
  position2: "Tech Lead, MERaLiON Team"
  position2_details: "National Multimodal LLM Programme (NMLP), S$70 million grant from NRF"
  position2_url: "https://www.imda.gov.sg/how-we-can-help/national-multimodal-llm-programme"
  period: "04/2023 - 04/2025"
  location: "Institute for Infocomm Research (I²R), A*STAR, Singapore"
  research_section:
    topics_summary: "I started my time at I²R, A*STAR focusing on dialogue summarization research. When the MERaLiON team was later formed to spearhead Singapore's national LLM project, I joined this elite group—honestly one of the sharpest teams at the institute, packed with top-tier PhDs and engineers. I took the lead on evaluation and data preparation for the AudioLLM workstream, focusing on making large models work across the diverse languages of Southeast Asia. It was a fast-paced journey that I wrapped up in 2025."
    research_topics:
      - title: "Dialogue Summarization"
        questions:
          - "How to effectively summarize multi-turn dialogues while preserving key information?"
          - "What techniques can improve coherence and factual consistency in dialogue summaries?"
      - title: "Making LLMs hear - AudioLLM"
        questions:
          - "What techniques can be used to effectively integrate audio processing capabilities into existing LLM architectures?"
          - "What is the most efficient approach for achieving seamless cross-modality integration?"
          - "What benchmarks can be designed to accurately evaluate the real-world performance of AudioLLMs?"
    publications:
      - name: "MERaLiON-AudioLLM: Bridging Audio and Language with Large Language Models"
        url: "https://aclanthology.org/2025.acl-demo.3/"
        venue: "ACL 2025"
      - name: "AudioBench: A Universal Benchmark for Audio Large Language Models"
        url: "https://aclanthology.org/2025.naacl-long.218/"
        venue: "NAACL 2025"
      - name: "Instructive Dialogue Summarization with Query Aggregations"
        url: "https://aclanthology.org/2023.emnlp-main.474/"
        venue: "EMNLP 2023"
      - name: "CRAFT: Extracting and Tuning Cultural Instructions from the Wild"
        url: "https://aclanthology.org/2024.c3nlp-1.4/"
        venue: "C3NLP 2024"
      - name: "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models"
        url: "https://aclanthology.org/2024.findings-emnlp.604/"
        venue: "EMNLP Findings 2024"
      - name: "Resilience of Large Language Models for Noisy Instructions"
        url: "https://aclanthology.org/2024.findings-emnlp.697/"
        venue: "EMNLP Findings 2024"
      - name: "CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment"
        url: "https://aclanthology.org/2025.sumeval-2.2/"
        venue: "SUMEval 2025"
      - name: "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning"
        url: "https://aclanthology.org/2024.naacl-long.22/"
        venue: "NAACL 2024"
      - name: "SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages"
        url: "https://aclanthology.org/2024.emnlp-main.296/"
        venue: "EMNLP 2024"
      - name: "MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders"
        url: "https://ieeexplore.ieee.org/document/10888128"
        venue: "ICASSP 2025"
      - name: "CoinMath: Harnessing the Power of Coding Instruction for Math LLM"
        url: "https://aclanthology.org/2025.findings-acl.44/"
        venue: "ACL Findings 2025"
      - name: "Optimizing Cross-Modality Alignment Module for Audio Large Language Models"
        venue: "Data Intelligence 2025"
      - name: "MNSC: Advancing Singlish Speech Understanding with Carefully Curated Corpora"
        url: "https://arxiv.org/abs/2501.01034"
        venue: "ASRU 2025"
      - name: "Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia"
        url: "https://aclanthology.org/2025.acl-long.916/"
        venue: "ACL 2025"
      - name: "NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025"
        url: "https://www.isca-archive.org/mlcslm_2025/peng25_mlcslm.pdf"
        venue: "MLC-SLM 2025"
      - name: "Diversity and Complementarity of Speech Encoders across Diverse Tasks in a Multi-modal Large Language Model"
        venue: "ASRU 2025"
      - name: "Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over Multi-faceted Math Problems"
        url: "https://arxiv.org/abs/2505.15000"
        venue: "arXiv 2025"
      - name: "IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models"
        url: "https://arxiv.org/abs/2505.16774"
        venue: "AACL 2025"
      - name: "Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs"
        url: "https://arxiv.org/abs/2506.06820"
        venue: "AACL 2025"
      - name: "Train Multi-Modal LLMs to Understand Diverse Speech Paralinguistics by Distilling from Teachers with Meta-Information"
        venue: "AAAI 2026 Workshop on Audio-Centric AI"
    academic_services:
      - "Publication Chair: EMNLP 2023"
      - "Local Organizing Team: EMNLP 2023"
      - "Area Chair: ACL ARR (2024-2025)"
      - "Editor: APSIPA Transactions on Signal and Information Processing"
      - "Reviewer: ACL, EMNLP, NAACL, ICASSP, IEEE TASLP"
    awards:
      - name: "Best Paper Award ($300)"
        description: "SUMEval Workshop, COLING 2025"
      - name: "Best Paper Award ($200)"
        description: "C3NLP Workshop, ACL 2024"
    students:
      - name: "Pham The Binh Minh"
        degree: "Undergraduate Research Intern"
        affiliation: "NTU, Singapore"
        period: "2025-01 - 2025-05"
        topic: "Multimodal AudioLLMs."
      - name: "Yiming Gao"
        degree: "Undergraduate Research Intern"
        affiliation: "NTU, Singapore"
        period: "2025-01 - 2025-05"
        topic: "Instruction following capability for multimodal large language models."
        publication: "AACL 2025"
      - name: "Tey Xue Cong"
        degree: "A*STAR Scholar Intern"
        supervisor: "Xunlong Zou"
        affiliation: "Ngee Ann Polytechnic, Singapore"
        period: "2025-02 - 2025-04"
        topic: "Multilingual speech data collection and processing."
      - name: "Jayden Lum"
        degree: "A*STAR Scholar Intern"
        supervisor: "Xunlong Zou"
        affiliation: "Ngee Ann Polytechnic, Singapore"
        period: "2025-02 - 2025-04"
        topic: "Multilingual speech data collection and processing."
      - name: "Yanchao Li"
        degree: "ACIS PhD Scholar"
        supervisor: "Nancy F. Chen"
        affiliation: "NTU, Singapore"
        period: "2024-01 - 2025-04"
        topic: "Long video understanding."
      - name: "Ziyi Xu"
        degree: "Research Intern"
        supervisor: "Sun Shuo"
        affiliation: "NUS, Singapore"
        period: "2024-07 - 2024-12"
        topic: "Multimodal alignment data collection and filtering."
      - name: "Ayrton San Joaquin"
        degree: "Research Associate"
        affiliation: "DesCarte@CREATE, Singapore"
        period: "2023-09 - 2024-08"
        topic: "Efficient training of large language models through gradient estimation."
        publication: "EMNLP 2024 Findings"
      - name: "Anh Thuc Nguyen"
        degree: "Research Intern"
        affiliation: "UNC Chapel Hill, USA"
        period: "2024-01 - 2024-05"
        topic: "Question generation for MERaLiON project and evaluation dataset creation."
  videos:
    - title: "MERaLiON Introduction"
      url: "https://www.youtube.com/embed/nBA3MqwjN3I"
      description: "Introduction to MERaLiON project."
    - title: "MERaLiON Demo"
      url: "https://www.youtube.com/embed/HZSa7vT73Lg"
      description: "Demo of MERaLiON AudioLLM capabilities."
  talks:
    - date: "2025.03"
      event: "Lorong AI, Singapore"
      title: "Evaluation on Audio-LLMs and Beyond"
      slides: "/assets/data/AudioBench_for_Lorong_AI.pdf"

nus:
  position: "Research Fellow"
  period: "09/2021 - 03/2023"
  location: "National University of Singapore (NUS)"
  supervisor: "Haizhou Li (IEEE Fellow)"
  supervisor_url: "https://scholar.google.com/citations?user=z8_x7C8AAAAJ&hl=en"
  research_section:
    topics_summary: "After completing my studies at the University of Southern California (USC), I have joined the National University of Singapore (NUS) as a Postdoctoral Researcher. This transition marks my first time living and working in Singapore, providing a fresh perspective to my academic career. Building upon my foundation in representation learning, my current research focuses on advancing dialogue-based technologies, with a specific emphasis on dialogue summarization and embedding evaluation methods."
    publications:
      - name: "Zero-Shot Relation Classification Through Inference on Category Attributes"
        url: "https://ieeexplore.ieee.org/document/10721241"
        venue: "IEEE TNNLS 2024"
      - name: "Relational Sentence Embedding for Flexible Semantic Matching"
        url: "https://aclanthology.org/2023.repl4nlp-1.20/"
        venue: "RepL4NLP 2023"
      - name: "Speech-Aware Multi-Domain Dialogue State Generation with ASR Error Correction Modules"
        url: "https://aclanthology.org/2023.dstc-1.13/"
        venue: "DSTC 2023"
      - name: "Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation"
        url: "https://arxiv.org/abs/2305.13785"
        venue: "arXiv 2023"
      - name: "Just Rank: Rethinking Evaluation with Word and Sentence Similarities"
        url: "https://aclanthology.org/2022.acl-long.419/"
        venue: "ACL 2022"
      - name: "Analyzing and Evaluating Faithfulness in Dialogue Summarization"
        url: "https://aclanthology.org/2022.emnlp-main.325/"
        venue: "EMNLP 2022"
      - name: "Generate, Discriminate and Contrast: A Semi-Supervised Sentence Representation Learning Framework"
        url: "https://aclanthology.org/2022.emnlp-main.558/"
        venue: "EMNLP 2022"
      - name: "A Focused Study on Sequence Length for Dialogue Summarization"
        url: "https://arxiv.org/abs/2209.11910"
        venue: "arXiv 2022"
    academic_services:
      - "Reviewer: IEEE/ACM TASLP, ACL ARR, NAACL, EMNLP, ICME"
      - "Reviewer: Nature (Human Behavior) 2022"
      - "Session Chair: IJCNN 2021"
      - "Organizational Volunteer: IALP 2022"
      - "Organizational Volunteer: CLSW 2023"
    students:
      - name: "Yan Xiao"
        degree: "Ph.D."
        affiliation: "Donghua University, China"
        period: "2023-02 - 2024-02"
        topic: "Relation extraction from text"
        publication: "IEEE TNNLS"

jd:
  position: "Research Intern"
  period: "05/2020 - 08/2020"
  location: "JD AI Research, Mountain View, USA"
  supervisors:
    - name: "Dr. Jing Huang"
      url: "https://scholar.google.com/citations?user=ocPXoIkAAAAJ&hl=en"
    - name: "Dr. Guangtao Wang"
      url: "https://scholar.google.com/citations?user=ga5aRGkAAAAJ&hl=en"
  collaboration: "<a href=\"https://cs.stanford.edu/people/jure/\" target=\"_blank\">Stanford University</a>"
  research_focus: "During my internship at JD AI Research, I focused on commonsense knowledge graph completion and inductive learning for knowledge representation."
  project_overview: "The research addressed a critical challenge in commonsense knowledge graphs (CKGs): how to perform knowledge graph completion for entities unseen during training (inductive learning). Traditional methods required retraining when new entities were added, which is impractical for large-scale CKGs."
  project_description: "We developed InductivE, a novel learning framework for inductive knowledge graph completion. The framework consists of three key components: a free-text encoder for processing entity descriptions, a graph encoder for capturing structural information, and a KG completion decoder for predicting missing relations."
  technical_work:
    - "Designed and implemented the InductivE framework for inductive commonsense knowledge graph completion"
    - "Developed free-text encoder using pre-trained language models to encode entity descriptions"
    - "Built graph neural network encoder to capture structural information from the knowledge graph"
    - "Implemented knowledge graph completion decoder for relation prediction"
    - "Conducted extensive experiments on ATOMIC and ConceptNet benchmarks"
  achievements:
    - "Achieved over 48% improvement in inductive scenarios compared to existing methods"
    - "State-of-the-art results on ATOMIC and ConceptNet benchmarks"
    - "Published research paper at IJCNN 2021 (International Joint Conference on Neural Networks)"
    - "Framework enables handling of unseen entities without model retraining"
  publication:
    title: "Inductive Learning on Commonsense Knowledge Graph Completion"
    authors: "Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, C.-C. Jay Kuo"
    venue: "IJCNN (International Joint Conference on Neural Networks)"
    year: "2021"
    arxiv: "https://arxiv.org/abs/2009.09263"

ontario:
  position: "Research Intern"
  period: "07/2016 - 10/2016"
  location: "Ontario Tech University, Canada"
  supervisor: "Prof. Haoxiang Lang"
  supervisor_url: "https://engineering.ontariotechu.ca/people/ame/haoxiang.lang.php"
  project_overview: "During my research internship at Ontario Tech University, I worked on a project involving 3D point cloud-based hand recognition using Kinect camera and its integration with robotics systems."
  project_description: "The project focused on developing a system that could recognize and track human hands in 3D space using point cloud data captured by a Kinect camera, and then integrate this recognition capability with robotic systems for human-robot interaction applications."
  technical_work:
    - "Utilized Kinect camera to capture 3D point cloud data of human hands"
    - "Developed algorithms for hand detection and recognition from point cloud data"
    - "Implemented point cloud processing techniques to extract hand features and gestures"
    - "Integrated the hand recognition system with robotic platforms for real-time interaction"
    - "Conducted experiments and validation of the system's accuracy and performance"
  achievements:
    - "Successfully implemented 3D hand recognition using point cloud data from Kinect camera"
    - "Developed a working prototype that integrated hand recognition with robotic systems"
    - "Gained hands-on experience with computer vision, 3D point cloud processing, and robotics"
    - "Contributed to research in human-robot interaction and gesture recognition"
  videos:
    - title: "Hand Recognition and Robot Integration"
      description: "This demo shows how hand gestures are used to send commands, allowing the robot to move to different positions based on recognized hand movements."
      url: "https://www.youtube.com/embed/qq9L5BcOeig"
    - title: "Hand Gesture Recognition: Number Recognition"
      description: "This demo demonstrates hand position recognition and tracking of hand movement speed simultaneously."
      url: "https://www.youtube.com/embed/etjiZT4aRaQ"
  awards:
    - name: "Mitacs Globalink Research Internship"
      description: "Awarded as the 3rd undergraduate student"
    - name: "Student Research Showcase 2016"
      description: "Represented the lab - Conducted demo and presentation with Katherine Pyra"
  publication:
    title: "Hand Gesture Recognition and Motion Estimation using the Kinect Sensor"
    authors: "Bin Wang, Yunze Li, Haoxiang Lang, Ying Wang"
    venue: "Mechatronic Systems and Control"
    year: "2020"

