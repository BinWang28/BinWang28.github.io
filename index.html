<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Bin Wang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-GQSE2H4QXE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GQSE2H4QXE');
</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Bin. Wang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="data/Resume_Bin.pdf">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="team.html">Team</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="teaching.html">Courses</a></div>
<div class="menu-category">Website</div>
<div class="menu-item"><a href="index_chinese.html">中文</a></div>
<div class="menu-item"><a href="statistics.html">Statistics</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Bin Wang</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://binwang.xyz/"><img src="data/profile.jpg" alt="alt text" width="210px" height="210px" /></a>&nbsp;</td>
<td align="left"><p>Scientist, PhD,
<br />
Aural & Language Intelligence Department <a href="https://www.a-star.edu.sg/i2r/research-capabilities/aural-language-intelligence" target=&ldquo;blank&rdquo;>(ALI)</a>, 
<br />
Institute for Infocomm Research <a href="https://www.a-star.edu.sg/i2r" target=&ldquo;blank&rdquo;>(I\(^2\)R)</a>, 
<br />
Agency for Science, Technology and Research <a href="https://www.a-star.edu.sg" target=&ldquo;blank&rdquo;>(A*STAR)</a>
<br />
Address: 1 Fusionopolis Way, #20-10, Connexis North Tower, Singapore 138632
<br />
Email: <i>bwang28c</i> [@] gmail.com & wang_bin / [@] i2r.a-star.edu.sg
<br />
[<a href="https://scholar.google.com/citations?user=jUrRMv4AAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a>]&nbsp;&nbsp;&nbsp;
[<a href="https://github.com/BinWang28" target=&ldquo;blank&rdquo;>GitHub</a>]&nbsp;&nbsp;&nbsp;
[<a href="https://huggingface.co/binwang" target=&ldquo;blank&rdquo;>HuggingFace</a>]&nbsp;&nbsp;&nbsp;
[<a href="https://www.linkedin.com/in/bin-wang-3b7054140/" target=&ldquo;blank&rdquo;>LinkedIn</a>]&nbsp;&nbsp;&nbsp;
[<a href="https://twitter.com/BinWang_Eng" target=&ldquo;blank&rdquo;>Twitter</a>]
</p>
</td></tr></table>
<h2>About Me</h2>
<p>I am a scientist at Aural & Language Intelligence Department, I2R, A*STAR. Before joing that, I was a research fellow at National University of Singapore (<a href="https://www.nus.edu.sg/" target=&ldquo;blank&rdquo;>NUS</a>) working with Prof. <a href="https://colips.org/~eleliha/" target=&ldquo;blank&rdquo;>Haizhou Li</a> from 2021-2023. I received my Ph.D. degree from University of Southern California (<a href="https://www.usc.edu/" target=&ldquo;blank&rdquo;>USC</a>) supervised by Prof. <a href="https://viterbi.usc.edu/directory/faculty/Kuo/Chung-Chieh" target=&ldquo;blank&rdquo;>C.-C. Jay Kuo</a> in 2021. My bachelor's degree is obtained from University of Electronic Science and Technology of China (<a href="https://en.uestc.edu.cn/" target=&ldquo;blank&rdquo;>UESTC</a>) in 2017.
<br />
I am working on multimodal LLMs, specifically focusing on models that can comprehend, interact with, and respond effectively to humans.
</p>
<h2>Highlights</h2>
<ul>
<li><p>2024.12&nbsp;We released <a href="https://huggingface.co/MERaLiON" target=&ldquo;blank&rdquo;>MERaLiON models</a>, the first audio-based large language model designed specifically for Singlish and other related tasks!
</p>
</li>
<li><p>2024-2026&nbsp;National LLM Project <a href="https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2023/sg-to-develop-southeast-asias-first-llm-ecosystem" target=&ldquo;blank&rdquo;>Press Coverage</a>
</p>
</li>
<li><p>2024&nbsp;AudioBench <a href="https://arxiv.org/abs/2406.16020" target=&ldquo;blank&rdquo;>for AudioLLM Evaluation</a>
</p>
</li>
<li><p>2024&nbsp;NAACL <a href="https://seaeval.github.io/" target=&ldquo;blank&rdquo;>SeaEval for Multilingual Evaluation</a>
</p>
</li>
<li><p>2023&nbsp;EMNLP <a href="https://github.com/BinWang28/InstructDS" target=&ldquo;blank&rdquo;>Instructive Dialogue Summarization</a>
</p>
</li>
</ul>
<h2>Research</h2>
<p>My research focus including but not limited to: 
</p>
<ul>
<li><p>Multimodal LLMs (Audio, Text, Vision)
</p>
</li>
<li><p>Natural Language Processing
</p>
</li>
<li><p>Conversatioal Systems
</p>
</li>
<li><p>Generation AI
</p>
</li>
<li><p>Representation Learning for Words, Sentences and (Knowledge) Graphs
</p>
</li>
</ul>
<p><a href="publications.html" target=&ldquo;blank&rdquo;>Find out more</a>.
</p>
<h2>Selected Publications </h2>
<ol>
<li><p>Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen. &ldquo;AudioBench: A Universal Benchmark for Audio Large Language Models.&rdquo; ArXiv, 2024. [<a href="https://arxiv.org/abs/2406.16020" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/AudioLLMs/AudioBench" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, AiTi Aw, Nancy F. Chen. &ldquo;SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.&rdquo; NAACL, 2024. [<a href="https://aclanthology.org/2024.naacl-long.22/" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/SeaEval/SeaEval" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang, Chen Zhang, Yan Zhang, Yiming Chen and Haizhou Li. &ldquo;Analyzing and Evaluating Faithfulness in Dialogue Summarization.&rdquo; EMNLP, 2022. [<a href="https://arxiv.org/abs/2210.11777" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/BinWang28/FacEval" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang, C.-C. Jay Kuo, and Haizhou Li. &ldquo;Just Rank: Rethinking Evaluation with Word and Sentence Similarities.&rdquo; ACL, 2022. [<a href="https://arxiv.org/abs/2203.02679" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/BinWang28/EvalRank-Embedding-Evaluation" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, and C.-C. Jay Kuo. &ldquo;Inductive learning on commonsense knowledge graph completion.&rdquo; IJCNN, 2021. [<a href="https://arxiv.org/abs/2009.09263" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/BinWang28/InductivE" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang, and C.-C. Jay Kuo. &ldquo;SBERT-WK: A sentence embedding method by dissecting bert-based word models.&rdquo; IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. [<a href="https://ieeexplore.ieee.org/document/9140343" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/BinWang28/SBERT-WK-Sentence-Embedding" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
<li><p>Bin Wang*, Angela Wang*, Fenxiao Chen, Yuncheng Wang, and C.-C. Jay Kuo. &ldquo;Evaluating word embedding models: methods and experimental results.&rdquo; APSIPA transactions on signal and information processing, 2019. [<a href="https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing/article/evaluating-word-embedding-models-methods-and-experimental-results/EDF43F837150B94E71DBB36B28B85E79" target=&ldquo;blank&rdquo;>paper</a>], [<a href="https://github.com/BinWang28/Word-Embedding-Eval" target=&ldquo;blank&rdquo;>code</a>]
</p>
</li>
</ol>
<p><a href="publications.html" target=&ldquo;blank&rdquo;>Full list of publications</a>.
</p>
<h2>Opportunities</h2>
<div class="infoblock">
<div class="blockcontent">
<p>We are actively looking for candidates working on Multimodal LLMs (text, audio, vision, etc.).
<br />
</p>
<ul>
<li><p>Research Interns (6 months or above preferred), 
<br />
</p>
<ul>
<li><p><a href="https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/singapore-international-pre-graduate-award-sipga" target=&ldquo;blank&rdquo;>SIPGA</a> for international (master / undergraduate) students.
</p>
</li>
<li><p><a href="https://www.a-star.edu.sg/Scholarships/for-undergraduate-studies/a-star-research-internship-award-aria" target=&ldquo;blank&rdquo;>ARIA</a> for Singaporean undergraduate students.
</p>
</li>
<li><p><a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme" target=&ldquo;blank&rdquo;>ARAP</a> for international Ph.D. students attachment for 1-2 years.
</p>
</li>
<li><p>Local students from NUS, NTU, SMU, SUTD, SIT, Polytechnic etc. please contact me directly for attachment to projects.
<br />
</p>
</li></ul>
</li>
<li><p>Ph.D. Students
<br />
</p>
<ul>
<li><p><a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies" target=&ldquo;blank&rdquo;>SIPGA, AGS, ACIS</a>
<br />
</p>
</li></ul>
</li>
<li><p>Long-term Positions
</p>
<ul>
<li><p>Research Engineer / Scientist (Both engineering and research background are preferred.)
</p>
</li>
</ul>

</li>
</ul>
</div></div>
<div id="footer">
<div id="footer-text">
Page generated 2025-01-22 11:20:36 +08, by jemdoc+MathJax.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
